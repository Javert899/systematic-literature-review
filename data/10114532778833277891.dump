{"status":"ok","message-type":"work","message-version":"1.0.0","message":{"indexed":{"date-parts":[[2019,10,26]],"date-time":"2019-10-26T12:10:29Z","timestamp":1572091829036},"publisher-location":"New York, New York, USA","reference-count":20,"publisher":"ACM Press","isbn-type":[{"value":"9781450360487","type":"print"}],"license":[{"URL":"http:\/\/www.acm.org\/publications\/policies\/copyright_policy#Background","start":{"date-parts":[[2018,11,4]],"date-time":"2018-11-04T00:00:00Z","timestamp":1541289600000},"delay-in-days":307,"content-version":"vor"}],"content-domain":{"domain":[],"crossmark-restriction":false},"short-container-title":[],"published-print":{"date-parts":[[2018]]},"DOI":"10.1145\/3277883.3277891","type":"proceedings-article","created":{"date-parts":[[2018,10,11]],"date-time":"2018-10-11T13:19:23Z","timestamp":1539263963000},"source":"Crossref","is-referenced-by-count":0,"title":["Beyond Pulse"],"prefix":"10.1145","author":[{"given":"Dan","family":"Li","sequence":"first","affiliation":[{"name":"SARI, CAS, Shanghai, China"}]},{"given":"Xiaoyuan","family":"Ma","sequence":"additional","affiliation":[{"name":"SARI, CAS & UCAS, Shanghai, China"}]},{"given":"Jianming","family":"Wei","sequence":"additional","affiliation":[{"name":"SARI, CAS, Shanghai, China"}]}],"member":"320","reference":[{"key":"key-10.1145\/3277883.3277891-1","unstructured":"Abdelkareem Bedri, David Byrd, Peter Presti, Himanshu Sahni, Zehua Gue, and Thad Starner. 2015. Stick it in your ear: Building an in-ear jaw movement sensor. In Adjunct Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2015 ACM International Symposium on Wearable Computers. ACM, 1333--1338."},{"key":"key-10.1145\/3277883.3277891-2","unstructured":"Abdelkareem Bedri, Himanshu Sahni, Pavleen Thukral, Thad Starner, David Byrd, Peter Presti, Gabriel Reyes, Maysam Ghovanloo, and Zehua Guo. 2015. Toward silent-speech control of consumer wearables. Computer 48, 10 (2015), 54--62.","DOI":"10.1109\/MC.2015.310","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3277883.3277891-3","unstructured":"Bruce Denby, Thomas Schultz, Kiyoshi Honda, Thomas Hueber, Jim M Gilbert, and Jonathan S Brumberg. 2010. Silent speech interfaces. Speech Communication 52, 4 (2010), 270--287.","DOI":"10.1016\/j.specom.2009.08.002","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3277883.3277891-4","unstructured":"L Diener, M Janke, and T Schultz. 2015. Direct conversion from facial myoelectric signals to speech using Deep Neural Networks. In International Joint Conference on Neural Networks. 1--7.","DOI":"10.1109\/IJCNN.2015.7280404","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3277883.3277891-5","unstructured":"James M. Gilbert, Jose A. Gonzalez, Lam A. Cheah, Stephen R. Ell, Phil Green, Roger K. Moore, and Ed Holdsworth. 2017. Restoring speech following total removal of the larynx by a learned transformation from sensor data to acoustics. The Journal of the Acoustical Society of America 141, 3 (2017), EL307--EL313.","DOI":"10.1121\/1.4978364","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3277883.3277891-6","unstructured":"Xueliang Huo, Hangue Park, Jeonghee Kim, and Maysam Ghovanloo. 2013. A dual-mode human computer interface combining speech and tongue motion for people with severe disabilities. IEEE Transactions on Neural Systems and Rehabilitation Engineering 21, 6 (2013), 979--991.","DOI":"10.1109\/TNSRE.2013.2248748","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3277883.3277891-7","unstructured":"Silicon Labs. 2015. Si1143 datasheet. https:\/\/www.silabs.com\/documents\/public\/datasheets\/Si114x.pdf."},{"key":"key-10.1145\/3277883.3277891-8","unstructured":"Zheng Li, Ryan Robucci, Nilanjan Banerjee, and Chintan Patel. 2015. Tongue-n-cheek: Non-contact tongue gesture recognition. In Proceedings of the 14th International Conference on Information Processing in Sensor Networks. ACM, 95--105.","DOI":"10.1145\/2737095.2737109","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3277883.3277891-9","unstructured":"Juergen Luettin and St&#233;phane Dupont. 1998. Continuous audio-visual speech recognition. In Proceedings of the 5th European Conference on Computer Vision-Volume II- Volume II. Springer-Verlag, 657--673.","DOI":"10.1007\/BFb0054771","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3277883.3277891-10","unstructured":"Balz Maag, Zimu Zhou, Olga Saukh, and Lothar Thiele. 2017. BARTON: Low power tongue movement sensing with in-Ear barometers. In Proceedings of the 2017 IEEE 23rd International Conference on Parallel and Distributed Systems (IC-PADS). IEEE, 9--16.","DOI":"10.1109\/ICPADS.2017.00013","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3277883.3277891-11","unstructured":"Denys J. C. Matthies, Bernhard A. Strecker, and Bodo Urban. 2017. Earfieldsensing: A novel in-ear electric field sensing to enrich wearable gesture input through facial expressions. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 1911--1922.","DOI":"10.1145\/3025453.3025692","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3277883.3277891-12","unstructured":"Geoffrey S Meltzner, James T Heaton, Yunbin Deng, Gianluca De Luca, Serge H Roy, and Joshua C Kline. 2017. Silent speech recognition as an alternative communication device for persons with laryngectomy. IEEE\/ACM Transactions on Audio, Speech, and Language Processing 25, 12 (2017), 2386--2398."},{"key":"key-10.1145\/3277883.3277891-13","unstructured":"Geoffrey S Meltzner, James T Heaton, Yunbin Deng, Gianluca De Luca, Serge H Roy, and Joshua C Kline. 2018. Development of sEMG sensors and algorithms for silent speech recognition. Journal of Neural Engineering 15, 4 (2018), 046031."},{"key":"key-10.1145\/3277883.3277891-14","unstructured":"Hunny Pahuja, Priya Ranjan, and Amit Ujlayan. 2017. Audio visual automatic speech recognition using multi-tasking learning of deep neural networks. In Proceedings of the 2017 International Conference on Infocom Technologies and Unmanned Systems (Trends and Future Directions) (ICTUS). IEEE, 455--458."},{"key":"key-10.1145\/3277883.3277891-15","unstructured":"Kate Saenko, Karen Livescu, Michael Siracusa, Kevin Wilson, James Glass, and Trevor Darrell. 2005. Visual speech recognition with loosely synchronized feature streams. In Proceedings of the Tenth IEEE International Conference on Computer Vision - Volume 2. IEEE, 1424--1431.","DOI":"10.1109\/ICCV.2005.251","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3277883.3277891-16","unstructured":"Himanshu Sahni, Abdelkareem Bedri, Gabriel Reyes, Pavleen Thukral, Zehua Guo, Thad Starner, and Maysam Ghovanloo. 2014. The tongue and ear interface: A wearable system for silent speech recognition. In Proceedings of the 2014 ACM International Symposium on Wearable Computers. ACM, 47--54.","DOI":"10.1145\/2634317.2634322","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3277883.3277891-17","unstructured":"OSRAM Opto Semiconductors. 2018. SFH4640 datasheet. https:\/\/dammedia.osram.info\/media\/resource\/hires\/osram-dam-6001076\/SFH."},{"key":"key-10.1145\/3277883.3277891-18","unstructured":"Jiayao Tan, Cam Tu Nguyen, and Xiaoliang Wang. 2017. SilentTalk: Lip reading through ultrasonic sensing on mobile phones. In Proceedings of the IEEE INFOCOM 2017 - IEEE Conference on Computer Communications. IEEE, 1--9."},{"key":"key-10.1145\/3277883.3277891-19","unstructured":"Kazuhiro Taniguchi, Hisashi Kondo, Mami Kurosawa, and Atsushi Nishikawa. 2018. Earable TEMPO: A novel, hands-free input device that uses the movement of the tongue measured with a wearable ear sensor. Sensors 18, 3 (2018), 733."},{"key":"key-10.1145\/3277883.3277891-20","unstructured":"Tianming Zhao, Jian Liu, Yan Wang, Hongbo Liu, and Yingying Chen. 2018. PPG-based finger-level gesture recognition leveraging wearables. In Proceedings of the IEEE INFOCOM 2018 - IEEE Conference on Computer Communications. IEEE, 1457--1465."}],"event":{"name":"the 7th International Workshop","location":"Shenzhen, China","sponsor":["SIGCOMM, ACM Special Interest Group on Data Communication","SIGMOBILE, ACM Special Interest Group on Mobility of Systems, Users, Data and Computing","SIGARCH, ACM Special Interest Group on Computer Architecture","SIGBED, ACM Special Interest Group on Embedded Systems","SIGMETRICS, ACM Special Interest Group on Measurement and Evaluation","SIGOPS, ACM Special Interest Group on Operating Systems"],"acronym":"RealWSN'18","number":"7","start":{"date-parts":[[2018,11,4]]},"end":{"date-parts":[[2018,11,4]]}},"container-title":["Proceedings of the 7th International Workshop on Real-World Embedded Wireless Systems and Networks - RealWSN'18"],"original-title":[],"link":[{"URL":"http:\/\/dl.acm.org\/ft_gateway.cfm?id=3277891&ftid=2008165&dwn=1","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2019,10,26]],"date-time":"2019-10-26T11:56:22Z","timestamp":1572090982000},"score":1.0,"subtitle":["Can the in-Ear Photoplethysmogram Signal Understand What You Say?"],"short-title":[],"issued":{"date-parts":[[2018]]},"ISBN":["9781450360487"],"references-count":20,"URL":"http:\/\/dx.doi.org\/10.1145\/3277883.3277891","relation":{"cites":[]}}}