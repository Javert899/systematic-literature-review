{"status":"ok","message-type":"work","message-version":"1.0.0","message":{"indexed":{"date-parts":[[2019,10,5]],"date-time":"2019-10-05T18:40:30Z","timestamp":1570300830287},"publisher-location":"New York, New York, USA","reference-count":38,"publisher":"ACM Press","isbn-type":[{"value":"9781450355438","type":"print"}],"license":[{"URL":"http:\/\/www.acm.org\/publications\/policies\/copyright_policy#Background","start":{"date-parts":[[2017,11,3]],"date-time":"2017-11-03T00:00:00Z","timestamp":1509667200000},"delay-in-days":306,"content-version":"vor"}],"content-domain":{"domain":[],"crossmark-restriction":false},"short-container-title":[],"published-print":{"date-parts":[[2017]]},"DOI":"10.1145\/3136755.3136796","type":"proceedings-article","created":{"date-parts":[[2017,11,6]],"date-time":"2017-11-06T13:30:29Z","timestamp":1509975029000},"source":"Crossref","is-referenced-by-count":1,"title":["Evaluating content-centric vs. user-centric ad affect recognition"],"prefix":"10.1145","author":[{"given":"Abhinav","family":"Shukla","sequence":"first","affiliation":[{"name":"IIIT Hyderabad, India"}]},{"given":"Shruti Shriya","family":"Gullapuram","sequence":"additional","affiliation":[{"name":"IIIT Hyderabad, India"}]},{"given":"Harish","family":"Katti","sequence":"additional","affiliation":[{"name":"Indian Institute of Science, India"}]},{"given":"Karthik","family":"Yadati","sequence":"additional","affiliation":[{"name":"Delft University of Technology, Netherlands"}]},{"given":"Mohan","family":"Kankanhalli","sequence":"additional","affiliation":[{"name":"National University of Singapore, Singapore"}]},{"given":"Ramanathan","family":"Subramanian","sequence":"additional","affiliation":[{"name":"University of Glasgow at Singapore, Singapore"}]}],"member":"320","reference":[{"key":"key-10.1145\/3136755.3136796-1","unstructured":"M. K. Abadi, R. Subramanian, S. M. Kia, P. Avesani, I. Patras, and N. Sebe. 2015. DECAF: MEG-Based Multimodal Database for Decoding Affective Physiological Responses. IEEE Trans. Affective Computing 6, 3 (2015), 209&#8211;222.","DOI":"10.1109\/TAFFC.2015.2392932","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-2","unstructured":"Tuka AlHanai and Mohammad Ghassemi. 2017. Predicting Latent Narrative Mood Using Audio and Physiologic Data. In AAAI Conference on Artificial Intelligence."},{"key":"key-10.1145\/3136755.3136796-3","unstructured":"Yoann Baveye. 2015. Automatic prediction of emotions induced by movies. Theses. Ecole Centrale de Lyon."},{"key":"key-10.1145\/3136755.3136796-4","unstructured":"Yoann Baveye, Emmanuel Dellandrea, Christel Chamaret, and Liming Chen. 2015. LIRIS-ACCEDE: A video database for affective content analysis. IEEE Trans. Affective Computing 6, 1 (2015), 43&#8211;55.","DOI":"10.1109\/TAFFC.2015.2396531","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-5","unstructured":"Yoav Benjamini and Yosef Hochberg. 1995. Controlling the false discovery rate: a practical and powerful approach to multiple testing. J. Royal Stat. Soc. Series B (Methodological) 57, 1 (1995), 289&#8211;300."},{"key":"key-10.1145\/3136755.3136796-6","unstructured":"Maneesh Bilalpur, Seyed Mostafa Kia, Tat-Seng Chua, and Ramanathan Subramanian. 2017. Discovering Gender Differences in Facial Emotion Recognition via Implicit Behavioral Cues. In Affective Computing &#38; Intelligent Interaction.","DOI":"10.1109\/ACII.2017.8273588","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-7","unstructured":"Christopher M. Bishop. 2013. Pattern Recognition and Machine Learning. Vol. 53. Springer."},{"key":"key-10.1145\/3136755.3136796-8","unstructured":"M. K. Greenwald, E. W. Cook, and P. J. Lang. 1989. Affective judgement and psychophysiological response: dimensional covariation in the evaluation of pictorial stimuli. Journal of Psychophysiology 3 (1989), 51&#8211;64."},{"key":"key-10.1145\/3136755.3136796-9","unstructured":"Alan Hanjalic and Li-Quan Xu. 2005. Affective Video Content Representation. IEEE Trans. Multimedia 7, 1 (2005), 143&#8211;154."},{"key":"key-10.1145\/3136755.3136796-10","unstructured":"Morris B Holbrook, Rajeev Batra, and Rajeev Batra. 1987. Assessing the Role of Emotions as Mediators of Consumer Responses to Advertising. Journal of Consumer Research 14, 3 (1987), 404&#8211;420."},{"key":"key-10.1145\/3136755.3136796-11","unstructured":"Morris B Holbrook and John O Shaughnessy. 1984. The role of emotlon in advertising. Psychology &#38; Marketing 1, 2 (1984), 45&#8211;64.","DOI":"10.1002\/mar.4220010206","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-12","unstructured":"Zhengwei Huang, Ming Dong, Qirong Mao, and Yongzhao Zhan. 2014. Speech Emotion Recognition Using CNN. In ACM Multimedia. 801&#8211;804.","DOI":"10.1145\/2647868.2654984","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-13","unstructured":"Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell. 2014. CAFFE: Convolutional Architecture for Fast Feature Embedding. In ACM Int&#8217;l Conference on Multimedia. 675&#8211;678.","DOI":"10.1145\/2647868.2654889","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-14","unstructured":"Hideo Joho, Jacopo Staiano, Nicu Sebe, and Joemon M Jose. 2011. Looking at the viewer: analysing facial activity to detect personal highlights of multimedia contents. Multimedia Tools and Applications 51, 2 (2011), 505&#8211;523.","DOI":"10.1007\/s11042-010-0632-x","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-15","unstructured":"Mohan Kankanhalli Karthik Yadati and, Harish Katti and. 2013. Interactive Video Advertising: A Multimodal Affective Approach. Multimedia Modeling (MMM 13) (2013)."},{"key":"key-10.1145\/3136755.3136796-16","unstructured":"Harish Katti, Marius V. Peelen, and S. P. Arun. 2016. Object detection can be improved using human-derived contextual expectations. CoRR abs\/1611.07218 (2016)."},{"key":"key-10.1145\/3136755.3136796-17","unstructured":"Harish Katti, Anoop Kolar Rajagopal, Kalapathi Ramakrishnan, Mohan Kankanhalli, and Tat-Seng Chua. 2013. Online estimation of evolving human visual interest. ACM Transactions on Multimedia 11, 1 (2013).","DOI":"10.1145\/2632284","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-18","unstructured":"Harish Katti, Ramanathan Subramanian, Mohan Kankanhalli, Nicu Sebe, Tat-Seng Chua, and Kalpathi R Ramakrishnan. 2010. Making computers look the way we look: exploiting visual attention for image understanding. In ACM Int&#8217;l conference on Multimedia. 667&#8211;670.","DOI":"10.1145\/1873951.1874047","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-19","unstructured":"Aditya Khosla, Wilma A. Baingridge, Antonio Torralba, and Aude Oliva. 2013. Modifying the memorability of face photographs. International confernece on computer vision (ICCV) (2013).","DOI":"10.1109\/ICCV.2013.397","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-20","unstructured":"Sander Koelstra, Christian M&#252;hl, Mohammad Soleymani, Jong-Seok Lee, Ashkan Yazdani, Touradj Ebrahimi, Thierry Pun, Anton Nijholt, and Ioannis Patras. 2012."},{"key":"key-10.1145\/3136755.3136796-21","unstructured":"DEAP: A Database for Emotion Analysis Using Physiological Signals. IEEE Trans. Affective Computing 3, 1 (2012), 18&#8211;31.","DOI":"10.1109\/T-AFFC.2011.15","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-22","unstructured":"Sander Koelstra and Ioannis Patras. 2013. Fusion of facial expressions and EEG for implicit affective tagging. Image and Vision Computing 31, 2 (2013), 164&#8211;174.","DOI":"10.1016\/j.imavis.2012.10.002","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-23","unstructured":"Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. ImageNet Classification with Deep Convolutional Neural Networks. In Neural Information Processing Systems. 1097&#8211;1105."},{"key":"key-10.1145\/3136755.3136796-24","unstructured":"Peter J. Lang, Margaret M. Bradley, and B. N. Cuthbert. 2008. International affective picture system (IAPS): Affective ratings of pictures and instruction manual. Technical Report A-8. The Center for Research in Psychophysiology, University of Florida, Gainesville, FL."},{"key":"key-10.1145\/3136755.3136796-25","unstructured":"Chul Min Lee and Shrikanth S Narayanan. 2005. Toward detecting emotions in spoken dialogs. IEEE Transactions on Speech and Audio Processing 13, 2 (2005), 293&#8211;303."},{"key":"key-10.1145\/3136755.3136796-26","unstructured":"Tao Mei, Xian-Sheng Hua, Linjun Yang, and Shipeng Li. 2007. VideoSense: Towards Effective Online Video Advertising. In ACM Int&#8217;l Conference on Multimedia. 1075&#8211;1084.","DOI":"10.1145\/1291233.1291467","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-27","unstructured":"Danny Oude Bos. 2006. EEG-based emotion recognition - The Influence of Visual and Auditory Stimuli. In Capita Selecta (MSc course). University of Twente."},{"key":"key-10.1145\/3136755.3136796-28","unstructured":"Michel Tuan Pham, Maggie Geuens, and Patrick De Pelsmacker. 2013. The influence of ad-evoked feelings on brand evaluations: Empirical generalizations from consumer responses to more than 1000 {TV} commercials. International Journal of Research in Marketing 30, 4 (2013), 383 &#8211; 394.","DOI":"10.1016\/j.ijresmar.2013.04.004","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-29","unstructured":"Hamed R.-Tavakoli, Adham Atyabi, Antti Rantanen, Seppo J. Laukka, Samia Nefti-Meziani, and Janne Heikkila. 2015. Predicting the Valence of a Scene from Observers&#8217; Eye Movements. PLoS ONE 10, 9 (2015), 1&#8211;19.","DOI":"10.1371\/journal.pone.0141174","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-30","unstructured":"James Russell. 1980. A circumplex model of affect. (1980).","DOI":"10.1037\/h0077714","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-31","unstructured":"Abhinav Shukla, Shruti Shriya Gullapuram, Harish Katti, Karthik Yadati, Mohan Kankanhalli, and Ramanathan Subramanian. 2017. Affect Recognition in Ads with Application to Computational Advertising. In ACM Int&#8217;l conference on Multimedia.","DOI":"10.1145\/3123266.3123444","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-32","unstructured":"Ramanathan Subramanian, Harish Katti, Kalapathi Ramakrishnan, Mohan Kankanhalli, Tat-Seng Chua, and Nicu Sebe. 2010. An eye fixation database for saliency detection in images. In European Conference on Computer Vision.","DOI":"10.1007\/978-3-642-15561-1_3","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-33","unstructured":"Ramanathan Subramanian, Divya Shankar, Nicu Sebe, and David Melcher. 2014. Emotion modulates eye movement patterns and subsequent memory for the gist and details of movie scenes. Journal of vision 14, 3 (2014), 1&#8211;18.","DOI":"10.1167\/14.3.31","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-34","unstructured":"Ramanathan Subramanian, Julia Wache, Mojtaba Abadi, Radu Vieriu, Stefan Winkler, and Nicu Sebe. 2016. ASCERTAIN: Emotion and personality recognition using commercial sensors. IEEE Transactions on Affective Computing (2016)."},{"key":"key-10.1145\/3136755.3136796-35","unstructured":"Vassilios Vonikakis, Ramanathan Subramanian, Jonas Arnfred, and Stefan Winkler. 2017. A Probabilistic Approach to People-Centric Photo Selection and Sequencing. IEEE Transactions on Multimedia (2017).","DOI":"10.1109\/TMM.2017.2699859","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-36","unstructured":"Hee Lin Wang and Loong-Fah Cheong. 2006. Affective understanding in film. IEEE Trans. Circ. Syst. V. Tech. 16, 6 (2006), 689&#8211;704.","DOI":"10.1109\/TCSVT.2006.873781","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-37","unstructured":"Karthik Yadati, Harish Katti, and Mohan Kankanhalli. 2014. CAVVA: Computational affective video-in-video advertising. IEEE Trans. Multimedia 16, 1 (2014), 15&#8211;23.","DOI":"10.1109\/TMM.2013.2282128","doi-asserted-by":"crossref"},{"key":"key-10.1145\/3136755.3136796-38","unstructured":"Wei-Long Zheng, Jia-Yi Zhu, Yong Peng, and Bao-Liang Lu. 2014. EEG-based emotion classification using deep belief networks. IEEE International Conference on Multimedia &#38; Expo (2014).","DOI":"10.1109\/ICME.2014.6890166","doi-asserted-by":"crossref"}],"event":{"name":"the 19th ACM International Conference","location":"Glasgow, UK","sponsor":["SIGCHI, ACM Special Interest Group on Computer-Human Interaction"],"acronym":"ICMI 2017","number":"2017","start":{"date-parts":[[2017,11,13]]},"end":{"date-parts":[[2017,11,17]]}},"container-title":["Proceedings of the 19th ACM International Conference on Multimodal Interaction - ICMI 2017"],"original-title":[],"link":[{"URL":"http:\/\/dl.acm.org\/ft_gateway.cfm?id=3136796&ftid=1920531&dwn=1","content-type":"unspecified","content-version":"vor","intended-application":"similarity-checking"}],"deposited":{"date-parts":[[2019,10,5]],"date-time":"2019-10-05T18:03:15Z","timestamp":1570298595000},"score":1.0,"subtitle":[],"short-title":[],"issued":{"date-parts":[[2017]]},"ISBN":["9781450355438"],"references-count":38,"URL":"http:\/\/dx.doi.org\/10.1145\/3136755.3136796","relation":{"cites":[]}}}